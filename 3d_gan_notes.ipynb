{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from argparse import ArgumentParser\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"modelnet10.npz\", allow_pickle=True)\n",
    "train_voxel = data[\"train_voxel\"]  # Training 3D voxel samples\n",
    "test_voxel = data[\"test_voxel\"]  # Test 3D voxel samples\n",
    "train_labels = data[\"train_labels\"]  # Training labels (integers from 0 to 9)\n",
    "test_labels = data[\"test_labels\"]  # Test labels (integers from 0 to 9)\n",
    "class_map = data[\"class_map\"]  # Dictionary mapping the labels to their class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "\n",
    "# Plot a 3D voxel sample\n",
    "def plot_voxel(voxel, threshold=0.5):\n",
    "    binary_voxel = voxel > threshold\n",
    "    ax = plt.figure().add_subplot(projection=\"3d\")\n",
    "    ax.voxels(binary_voxel)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Count the number of correct predictions\n",
    "def count_correct_predictions(\n",
    "    predictions: torch.Tensor, threshold: float, is_greater=True\n",
    "):\n",
    "    if is_greater:\n",
    "        return torch.sum(predictions > threshold).float().sum()\n",
    "    else:\n",
    "        return torch.sum(predictions < threshold).float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    # Function from web: [https://github.com/black0017/3D-GAN-pytorch/blob/master/models/GAN3D.py]\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=512,\n",
    "        out_dim=64,\n",
    "        out_channels=1,\n",
    "        noise_dim=200,\n",
    "        activation=\"sigmoid\",\n",
    "    ):\n",
    "        super(Generator, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_dim = out_dim\n",
    "        self.in_dim = int(out_dim / 16)\n",
    "        conv1_out_channels = int(self.in_channels / 2.0)\n",
    "        conv2_out_channels = int(conv1_out_channels / 2)\n",
    "        conv3_out_channels = int(conv2_out_channels / 2)\n",
    "\n",
    "        self.linear = torch.nn.Linear(\n",
    "            noise_dim, in_channels * self.in_dim * self.in_dim * self.in_dim\n",
    "        )\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=conv1_out_channels,\n",
    "                kernel_size=(4, 4, 4),\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm3d(conv1_out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(\n",
    "                in_channels=conv1_out_channels,\n",
    "                out_channels=conv2_out_channels,\n",
    "                kernel_size=(4, 4, 4),\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm3d(conv2_out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(\n",
    "                in_channels=conv2_out_channels,\n",
    "                out_channels=conv3_out_channels,\n",
    "                kernel_size=(4, 4, 4),\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm3d(conv3_out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.ConvTranspose3d(\n",
    "                in_channels=conv3_out_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=(4, 4, 4),\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            )\n",
    "        )\n",
    "        if activation == \"sigmoid\":\n",
    "            self.out = torch.nn.Sigmoid()\n",
    "        else:\n",
    "            self.out = torch.nn.Tanh()\n",
    "\n",
    "    def project(self, x):\n",
    "        \"\"\"\n",
    "        projects and reshapes latent vector to starting volume\n",
    "        :param x: latent vector\n",
    "        :return: starting volume\n",
    "        \"\"\"\n",
    "        return x.view(-1, self.in_channels, self.in_dim, self.in_dim, self.in_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.project(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    # Function code based on: [https://github.com/black0017/3D-GAN-pytorch/blob/master/models/GAN3D.py]\n",
    "    def __init__(self, in_channels=1, dim=64, out_conv_channels=512):\n",
    "        super(Discriminator, self).__init__()\n",
    "        conv1_channels = int(out_conv_channels / 8)\n",
    "        conv2_channels = int(out_conv_channels / 4)\n",
    "        conv3_channels = int(out_conv_channels / 2)\n",
    "        self.out_conv_channels = out_conv_channels\n",
    "        self.out_dim = int(dim / 16)\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=conv1_channels,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm3d(conv1_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(\n",
    "                in_channels=conv1_channels,\n",
    "                out_channels=conv2_channels,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm3d(conv2_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(\n",
    "                in_channels=conv2_channels,\n",
    "                out_channels=conv3_channels,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm3d(conv3_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv3d(\n",
    "                in_channels=conv3_channels,\n",
    "                out_channels=out_conv_channels,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm3d(out_conv_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                out_conv_channels * self.out_dim * self.out_dim * self.out_dim, 1\n",
    "            ),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def get_representation(self, x):\n",
    "        conv1 = self.conv1(x)\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv3 = self.conv3(conv2)\n",
    "        conv4 = self.conv4(conv3)\n",
    "\n",
    "        # Create max pooling layers\n",
    "        maxpool2 = nn.MaxPool3d(kernel_size=8)\n",
    "        maxpool3 = nn.MaxPool3d(kernel_size=4)\n",
    "        maxpool4 = nn.MaxPool3d(kernel_size=2)\n",
    "\n",
    "        # Apply max pooling\n",
    "        pooled_conv2 = maxpool2(conv2)\n",
    "        pooled_conv3 = maxpool3(conv3)\n",
    "        pooled_conv4 = maxpool4(conv4)\n",
    "\n",
    "        # Concatenate along channels\n",
    "        concatenated_features = torch.cat(\n",
    "            [pooled_conv2, pooled_conv3, pooled_conv4], dim=1\n",
    "        )\n",
    "\n",
    "        # Flatten the concatenated features\n",
    "        features = concatenated_features.view(concatenated_features.size(0), -1)\n",
    "\n",
    "        return features\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        # Flatten and apply linear + sigmoid\n",
    "        x = x.view(\n",
    "            -1, self.out_conv_channels * self.out_dim * self.out_dim * self.out_dim\n",
    "        )\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task A: Show 5 samples from the dataset\n",
    "\n",
    "# Plot 5 samples from the dataset\n",
    "for i in range(5):\n",
    "    random_index = np.random.randint(0, len(train_voxel))\n",
    "    plot_voxel(train_voxel[random_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN3D(pl.LightningModule):\n",
    "    def __init__(self, noise_dim=200, g_lr=0.0025, d_lr=1e-5, b1=0.5, b2=0.999):\n",
    "        super(GAN3D, self).__init__()\n",
    "\n",
    "        # Set up model with parameters\n",
    "        self.noise_dim = noise_dim\n",
    "        self.generator = Generator(noise_dim=noise_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "        self.g_lr = g_lr\n",
    "        self.d_lr = d_lr\n",
    "        self.b1 = b1\n",
    "        self.b2 = b2\n",
    "        self.loss = nn.BCELoss()\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "        # For logging\n",
    "        self.generator_losses = []\n",
    "        self.discriminator_losses = []\n",
    "        self.total_losses = []\n",
    "        self.accumulated_correct = 0\n",
    "        self.accumulated_number_of_samples = 0\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def adversarial_loss(self, y_hat, y):\n",
    "        return self.loss(y_hat, y)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs = batch\n",
    "        imgs = imgs.to(self.device)\n",
    "        opt_g, opt_d = self.optimizers()\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = torch.ones(imgs.size(0), 1).to(self.device)\n",
    "        fake = torch.zeros(imgs.size(0), 1).to(self.device)\n",
    "\n",
    "        # Generate a batch of images\n",
    "        z = torch.randn(imgs.shape[0], self.noise_dim).to(self.device)\n",
    "        generated_imgs = self(z)\n",
    "\n",
    "        # Train Generator\n",
    "        discriminator_generated_imgs = self.discriminator(generated_imgs)\n",
    "        g_loss = self.adversarial_loss(discriminator_generated_imgs, valid)\n",
    "        g_loss.backward()\n",
    "        opt_g.step()\n",
    "        opt_g.zero_grad()\n",
    "\n",
    "        # Calculate discriminator accuracy\n",
    "        real_preds = self.discriminator(imgs)\n",
    "        fake_preds = self.discriminator(generated_imgs.detach())\n",
    "        correct_real = count_correct_predictions(real_preds, 0.5, is_greater=True)\n",
    "        correct_fake = count_correct_predictions(fake_preds, 0.5, is_greater=False)\n",
    "        total_correct = correct_real + correct_fake\n",
    "        accuracy = total_correct / (2 * imgs.size(0))\n",
    "\n",
    "        self.accumulated_correct += correct_real + correct_fake\n",
    "        self.accumulated_number_of_samples += imgs.size(0)\n",
    "\n",
    "        # Calculate discriminator loss\n",
    "        opt_d.zero_grad()\n",
    "        real_loss = self.adversarial_loss(real_preds, valid)\n",
    "        fake_loss = self.adversarial_loss(fake_preds, fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # Train Discriminator conditionally\n",
    "        if not hasattr(self, \"last_acc\") or self.last_acc <= 0.8:\n",
    "            d_loss.backward()\n",
    "            opt_d.step()\n",
    "\n",
    "        # Store current accuracy for next batch\n",
    "        self.last_acc = accuracy\n",
    "\n",
    "        # Log in tensorboard\n",
    "        self.log(\"g_loss\", g_loss)\n",
    "        self.log(\"d_loss\", d_loss)\n",
    "        loss = (g_loss + d_loss) / 2\n",
    "        self.log(\"loss\", loss)\n",
    "        self.generator_losses.append(g_loss.item())\n",
    "        self.discriminator_losses.append(d_loss.item())\n",
    "        self.total_losses.append(loss.item())\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_g = torch.optim.Adam(\n",
    "            self.generator.parameters(), lr=self.g_lr, betas=(self.b1, self.b2)\n",
    "        )\n",
    "        opt_d = torch.optim.Adam(\n",
    "            self.discriminator.parameters(), lr=self.d_lr, betas=(self.b1, self.b2)\n",
    "        )\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\n",
    "            \"Total correct\",\n",
    "            (self.accumulated_correct) / (self.accumulated_number_of_samples * 2),\n",
    "        )\n",
    "        self.accumulated_correct = 0\n",
    "        self.accumulated_number_of_samples = 0\n",
    "\n",
    "    # Plot losses\n",
    "    def plot_losses(self):\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.generator_losses, label=\"Generator Loss\")\n",
    "        plt.plot(self.discriminator_losses, label=\"Discriminator Loss\")\n",
    "        plt.plot(self.total_losses, label=\"Total Loss\")\n",
    "        plt.title(\"Training Losses\")\n",
    "        plt.xlabel(\"Batch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearClassifier(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-3, discriminator=None, num_classes=10):\n",
    "        super(LinearClassifier, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.lr = lr\n",
    "        self.linear = nn.Linear(\n",
    "            discriminator.get_representation(torch.randn(1, 1, 64, 64, 64)).shape[1],\n",
    "            num_classes,\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.linear(x))\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device).long()\n",
    "\n",
    "        opt = self.optimizers()\n",
    "\n",
    "        # Get features from discriminator\n",
    "        features = self.discriminator.get_representation(x)\n",
    "\n",
    "        logits = self(features.detach())\n",
    "        loss = self.loss(logits, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        self.log(\"train_loss\", loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device).long()\n",
    "\n",
    "        # Get features from discriminator\n",
    "        features = self.discriminator.get_representation(x)\n",
    "\n",
    "        logits = self(features)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device).long()\n",
    "\n",
    "        # Get features from discriminator\n",
    "        features = self.discriminator.get_representation(x)\n",
    "\n",
    "        logits = self(features)\n",
    "        loss = self.loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.float()),  # Convert tensor to float type\n",
    "        transforms.Lambda(\n",
    "            lambda x: x.unsqueeze(0) if len(x.shape) == 3 else x\n",
    "        ),  # Add channel dimension\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class VoxelDataset(Dataset):\n",
    "    def __init__(self, data, label, if_label=False, transform=None, desired_label=None):\n",
    "        self.if_label = if_label\n",
    "        if desired_label is not None:\n",
    "            indices = [i for i, l in enumerate(label) if l == desired_label]\n",
    "            self.data = [data[i] for i in indices]\n",
    "            self.label = [label[i] for i in indices]\n",
    "        else:\n",
    "            self.data = data\n",
    "            self.label = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        voxel = self.data[index]\n",
    "\n",
    "        if self.transform:\n",
    "            voxel = self.transform(voxel)\n",
    "\n",
    "        if self.if_label:\n",
    "            return voxel, self.label[index]\n",
    "\n",
    "        return voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create config for parameters\n",
    "parser = ArgumentParser(description=\"3D GAN\")\n",
    "\n",
    "parser.add_argument(\"--batch_size\", type=int, default=100)\n",
    "parser.add_argument(\"--epochs\", type=int, default=1)\n",
    "parser.add_argument(\"--g_lr\", type=float, default=0.0025)\n",
    "parser.add_argument(\"--d_lr\", type=float, default=1e-4)\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5)\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999)\n",
    "parser.add_argument(\"--noise_dim\", type=int, default=200)\n",
    "parser.add_argument(\"--classifier_lr\", type=float, default=1e-3)\n",
    "parser.add_argument(\"--classifier_epochs\", type=int, default=10)\n",
    "parser.add_argument(\"--desired_label\", type=int, default=None)\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the 3DGAN\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset\n",
    "train_dataset = VoxelDataset(\n",
    "    train_voxel,\n",
    "    train_labels,\n",
    "    transform=transform,\n",
    "    desired_label=args.desired_label,\n",
    "    if_label=False,\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "\n",
    "# Initialize the GAN\n",
    "model = GAN3D(\n",
    "    d_lr=args.d_lr, g_lr=args.g_lr, noise_dim=args.noise_dim, b1=args.b1, b2=args.b2\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Set logger\n",
    "tb_logger = TensorBoardLogger(\n",
    "    \"logs/\",\n",
    "    name=\"GAN3D\",\n",
    "    version=\"3DGAN_epochs={}_label={}.pt\".format(args.epochs, args.desired_label),\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = pl.Trainer(max_epochs=args.epochs, accelerator=\"gpu\", logger=tb_logger)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_loader,\n",
    "    ckpt_path=None,\n",
    ")\n",
    "\n",
    "# Task A: Save trained model for later use\n",
    "torch.save(\n",
    "    {\"model_state_dict\": model.state_dict(), \"config\": vars(args)},\n",
    "    \"3DGAN_epochs={}_label={}.pt\".format(args.epochs, args.desired_label),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task A: Present a figure of the history of the training loss of the discriminator and generator.\n",
    "model.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task A: Show the total number of parameters of the two models.\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Generator\n",
    "summary(model, (1, 200))\n",
    "\n",
    "# Discriminator\n",
    "summary(model.discriminator, (1, 64, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load 3DGAN model\n",
    "model = GAN3D(\n",
    "    d_lr=args.d_lr, g_lr=args.g_lr, noise_dim=args.noise_dim, b1=args.b1, b2=args.b2\n",
    ")\n",
    "model.load_state_dict(\n",
    "    torch.load(\"3DGAN_epochs={}_label={}.pt\".format(args.epochs, args.desired_label))[\n",
    "        \"model_state_dict\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize the classifier\n",
    "classifier = LinearClassifier(lr=args.classifier_lr, discriminator=model.discriminator)\n",
    "classifier = classifier.to(device)\n",
    "\n",
    "# Dataset\n",
    "train_dataset = VoxelDataset(\n",
    "    train_voxel,\n",
    "    train_labels,\n",
    "    transform=transform,\n",
    "    desired_label=args.desired_label,\n",
    "    if_label=True,\n",
    ")\n",
    "test_dataset = VoxelDataset(\n",
    "    test_voxel,\n",
    "    test_labels,\n",
    "    transform=transform,\n",
    "    desired_label=args.desired_label,\n",
    "    if_label=True,\n",
    ")\n",
    "\n",
    "# Split test dataset into train and validation\n",
    "test_size = int(0.8 * len(test_dataset))\n",
    "val_size = len(test_dataset) - test_size\n",
    "test_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    test_dataset, [test_size, val_size]\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "# Set logger\n",
    "tb_logger = TensorBoardLogger(\n",
    "    \"logs/\",\n",
    "    name=\"LinearClassifier\",\n",
    "    version=\"Classifier_epochs={}_3DGAN_epochs={}_label={}\".format(\n",
    "        args.classifier_epochs, args.epochs, args.desired_label\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=args.classifier_epochs, accelerator=\"gpu\", logger=tb_logger\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(classifier, train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "# Test the model\n",
    "trainer.test(classifier, test_loader)\n",
    "\n",
    "# Save model\n",
    "torch.save(\n",
    "    {\"model_state_dict\": classifier.state_dict(), \"config\": vars(args)},\n",
    "    \"Classifier_epochs={}_3DGAN_epochs={}.pt\".format(\n",
    "        args.classifier_epochs, args.epochs\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task A: Show 4 generated 3D voxel data using the trained generator model with different latent vector z.\n",
    "model = GAN3D()\n",
    "model.load_state_dict(\n",
    "    torch.load(\"3DGAN_epochs={}_label={}.pt\".format(args.epochs, args.desired_label))[\n",
    "        \"model_state_dict\"\n",
    "    ]\n",
    ")\n",
    "number_of_samples = 4\n",
    "z = torch.randn(number_of_samples, 200)\n",
    "for i in range(z.shape[0]):\n",
    "    generated_imgs = model(z)\n",
    "    plot_voxel(generated_imgs[i].detach().cpu().numpy().squeeze(), threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
